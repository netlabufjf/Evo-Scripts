{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geoplotlib\n",
    "from geoplotlib.utils import read_csv, BoundingBox, DataAccessObject\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "from shapely.geometry import shape, Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "travels = pd.read_csv('../travels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nome dos geojsons a serem comparados com as coordenadas\n",
    "json_name = ['vancouver', 'burnaby', 'sea-island', 'new-westminster',\n",
    "             'north-vancouver', 'grousewoods', 'university']\n",
    "geojsons = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for js in json_name:\n",
    "    with open('../travels_hotmap/'+js+'.json') as json_data:\n",
    "        geojsons.append(json.load(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os nomes dos distritos e agrupando em regioes em comum \n",
    "names = []\n",
    "group = []\n",
    "count = 0\n",
    "for json in geojsons:\n",
    "    count += 1\n",
    "    for feature in json['features']:\n",
    "\n",
    "        name = feature['properties']['name']\n",
    "        \n",
    "        if (name not in names):\n",
    "            group.append(count)\n",
    "            names.append(feature['properties']['name'])\n",
    "            \n",
    "names = pd.DataFrame(names, columns=['name'])\n",
    "names['group'] = pd.DataFrame(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Listando todas as possibilidades de saida e chegada\n",
    "\n",
    "links = []\n",
    "\n",
    "for i in range(len(names)):\n",
    "    for j in range(len(names)):\n",
    "        links.append([i,j])\n",
    "        \n",
    "links = pd.DataFrame(links, columns=['source', 'target'])\n",
    "links['value'] = [0]*len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contando a quantidade de viagens para cada trajeto\n",
    "\n",
    "# Lists that will store the start and end district names\n",
    "start_list = []\n",
    "end_list = []\n",
    "\n",
    "for (start_lon, start_lat, end_lon, end_lat, car_id) in zip(travels['Start_lon'], travels['Start_lat'], \n",
    "                                                    travels['End_lon'], travels['End_lat'], travels['Id']):\n",
    "        \n",
    "    start_point = Point(start_lon, start_lat)\n",
    "    end_point = Point(end_lon, end_lat)\n",
    "    start = end = None\n",
    "    start_name = end_name = None\n",
    "    found = False\n",
    "    \n",
    "    # Buscando em cada geojson se a viagem est√° em um certo distrito\n",
    "    \n",
    "    for json in geojsons:\n",
    "        if (not found):\n",
    "            \n",
    "            for feature in json['features']:\n",
    "                \n",
    "                polygon = shape(feature['geometry'])\n",
    "                \n",
    "                if polygon.contains(start_point):\n",
    "                    # Coletando o distrito de saida\n",
    "                    start = names[names['name'] == feature['properties']['name']].index[0]\n",
    "                    start_name = feature['properties']['name']\n",
    "                    found = True\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "                \n",
    "    found = False\n",
    "                \n",
    "    for json in geojsons:\n",
    "        if (not found):\n",
    "            \n",
    "            for feature in json['features']:\n",
    "                \n",
    "                polygon = shape(feature['geometry'])\n",
    "                \n",
    "                if polygon.contains(end_point):\n",
    "                    # Coletando o distrito de chegada\n",
    "                    end = names[names['name'] == feature['properties']['name']].index[0]\n",
    "                    end_name = feature['properties']['name']\n",
    "                    found = True\n",
    "                    break\n",
    "                    \n",
    "        else:\n",
    "            break\n",
    "            \n",
    "                    \n",
    "    # Somando mais uma viagem no trajeto\n",
    "    links['value'].loc[(links['source'] == start) & (links['target'] == end)] += 1\n",
    "    start_list.append(start_name)\n",
    "    end_list.append(end_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "travels['start_district'] = start_list\n",
    "travels['end_district'] = end_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_time</th>\n",
       "      <th>End_time</th>\n",
       "      <th>Id</th>\n",
       "      <th>Start_lat</th>\n",
       "      <th>Start_lon</th>\n",
       "      <th>End_lat</th>\n",
       "      <th>End_lon</th>\n",
       "      <th>Maps_duration</th>\n",
       "      <th>Real_duration</th>\n",
       "      <th>Fuel_start</th>\n",
       "      <th>Fuel_end</th>\n",
       "      <th>start_district</th>\n",
       "      <th>end_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-03-01 08:26:55.380077-08:00</td>\n",
       "      <td>2018-03-01 08:33:09.325978-08:00</td>\n",
       "      <td>JTDKDTB38H1597538</td>\n",
       "      <td>49.259346</td>\n",
       "      <td>-123.122070</td>\n",
       "      <td>49.262367</td>\n",
       "      <td>-123.113274</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>6.232432</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "      <td>Fairview</td>\n",
       "      <td>Mount Pleasant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-01 08:26:55.380077-08:00</td>\n",
       "      <td>2018-03-01 08:33:09.325978-08:00</td>\n",
       "      <td>JTDKDTB35J1606797</td>\n",
       "      <td>49.249508</td>\n",
       "      <td>-123.137482</td>\n",
       "      <td>49.249508</td>\n",
       "      <td>-123.137482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.232432</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>Shaughnessy</td>\n",
       "      <td>Shaughnessy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-03-01 08:26:55.380077-08:00</td>\n",
       "      <td>2018-03-01 08:36:16.682113-08:00</td>\n",
       "      <td>JTDKDTB33H1598015</td>\n",
       "      <td>49.270780</td>\n",
       "      <td>-123.071480</td>\n",
       "      <td>49.270780</td>\n",
       "      <td>-123.071480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.355034</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>Grandview-Woodland</td>\n",
       "      <td>Grandview-Woodland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-01 08:30:02.405985-08:00</td>\n",
       "      <td>2018-03-01 08:36:16.682113-08:00</td>\n",
       "      <td>JTDKDTB32F1111738</td>\n",
       "      <td>49.256530</td>\n",
       "      <td>-123.186462</td>\n",
       "      <td>49.256530</td>\n",
       "      <td>-123.186462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.237935</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>Dunbar Southlands</td>\n",
       "      <td>Dunbar Southlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-03-01 08:26:55.380077-08:00</td>\n",
       "      <td>2018-03-01 08:39:23.591149-08:00</td>\n",
       "      <td>JTDKDTB34H1598038</td>\n",
       "      <td>49.254760</td>\n",
       "      <td>-123.097260</td>\n",
       "      <td>49.254760</td>\n",
       "      <td>-123.097260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.470185</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>Riley Park</td>\n",
       "      <td>Riley Park</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Start_time                          End_time  \\\n",
       "0  2018-03-01 08:26:55.380077-08:00  2018-03-01 08:33:09.325978-08:00   \n",
       "1  2018-03-01 08:26:55.380077-08:00  2018-03-01 08:33:09.325978-08:00   \n",
       "2  2018-03-01 08:26:55.380077-08:00  2018-03-01 08:36:16.682113-08:00   \n",
       "3  2018-03-01 08:30:02.405985-08:00  2018-03-01 08:36:16.682113-08:00   \n",
       "4  2018-03-01 08:26:55.380077-08:00  2018-03-01 08:39:23.591149-08:00   \n",
       "\n",
       "                  Id  Start_lat   Start_lon    End_lat     End_lon  \\\n",
       "0  JTDKDTB38H1597538  49.259346 -123.122070  49.262367 -123.113274   \n",
       "1  JTDKDTB35J1606797  49.249508 -123.137482  49.249508 -123.137482   \n",
       "2  JTDKDTB33H1598015  49.270780 -123.071480  49.270780 -123.071480   \n",
       "3  JTDKDTB32F1111738  49.256530 -123.186462  49.256530 -123.186462   \n",
       "4  JTDKDTB34H1598038  49.254760 -123.097260  49.254760 -123.097260   \n",
       "\n",
       "   Maps_duration  Real_duration  Fuel_start  Fuel_end      start_district  \\\n",
       "0       4.416667       6.232432          52        58            Fairview   \n",
       "1       0.000000       6.232432          85        85         Shaughnessy   \n",
       "2       0.000000       9.355034          85        85  Grandview-Woodland   \n",
       "3       0.000000       6.237935          64        64   Dunbar Southlands   \n",
       "4       0.000000      12.470185          77        77          Riley Park   \n",
       "\n",
       "         end_district  \n",
       "0      Mount Pleasant  \n",
       "1         Shaughnessy  \n",
       "2  Grandview-Woodland  \n",
       "3   Dunbar Southlands  \n",
       "4          Riley Park  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "travels.to_csv('../travels_hotmap/travels_district.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "travels = pd.read_csv('../travels_hotmap/travels_district.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links.to_csv('travels_hotmap/links.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links = pd.read_csv('travels_hotmap/links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizando os dados de viagens como um fluxo de √≠ndice da linha para o da coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluxo de todas as intera√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux = pd.DataFrame()\n",
    "for i in range(len(names)):\n",
    "    flux[i] = [0] * len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(links)):\n",
    "    source = links['source'].iloc[i] \n",
    "    target = links['target'].iloc[i]\n",
    "    \n",
    "    flux[target].iloc[source] += links['value'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux.index = list(names['name'])\n",
    "flux.columns = list(names['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux.to_csv('travels_hotmap/flux.csv', sep=' ', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluxo de viagens fora de Vancouver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux = pd.DataFrame()\n",
    "for i in range(names['group'].max()):\n",
    "    flux[i] = [0] * names['group'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(links)):\n",
    "    source = names['group'].iloc[links['source'].iloc[i]] - 1\n",
    "    target = names['group'].iloc[links['target'].iloc[i]] - 1\n",
    "    \n",
    "    flux[target].iloc[source] += links['value'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux.index = list(json_name)\n",
    "flux.columns = list(json_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux.to_csv('travels_hotmap/fluxOutVancouver.csv', sep=' ', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluxo de viagens dentro de Vancouver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "districts = names[names['group'] == 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux = pd.DataFrame()\n",
    "for i in range(len(districts)):\n",
    "    flux[i] = [0] * len(districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links_districts = links[(links['source'] < len(districts)) & (links['target'] < len(districts))]\n",
    "for i in range(len(links_districts)):\n",
    "    source = links_districts['source'].iloc[i]\n",
    "    target = links_districts['target'].iloc[i]\n",
    "    \n",
    "    flux[target].iloc[source] += links_districts['value'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux.index = list(names[names['group'] == 1]['name'])\n",
    "flux.columns = list(names[names['group'] == 1]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flux.to_csv('travels_hotmap/fluxInVancouver.csv', sep=' ', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluxo de viagens por hor√°rios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_datetime(df_time):\n",
    "    \"\"\" \n",
    "    Reformatando de string para datetime.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_time : pandas.DataFrame, string\n",
    "        Dataframe com strings a serem convertidas para datetime.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    date_list : pandas.DataFrame, datetime\n",
    "        Dataframe com valores em datetime para poss√≠veis fusos de Vancouver.\n",
    "    \n",
    "    \"\"\"\n",
    "    date_list = []\n",
    "    \n",
    "    # Formatos de fuso hor√°rio comum de Vancouver e \n",
    "    # fuso hor√°rio caracter√≠stico de hor√°rio de ver√£o\n",
    "    format_string = ['%Y-%m-%d %H:%M:%S.%f-08:00', '%Y-%m-%d %H:%M:%S.%f-07:00',\n",
    "                     '%Y-%m-%d %H:%M:%S-08:00', '%Y-%m-%d %H:%M:%S-07:00']\n",
    "    \n",
    "    \n",
    "    for date in df_time:\n",
    "        for fmt in format_string:\n",
    "            try:\n",
    "                date_list.append(datetime.datetime.strptime(str(date), fmt))\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    \n",
    "    return pd.DataFrame(date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para calcular distancia entre coordenadas\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    m = 6367 * c * 1000\n",
    "\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "travels['Start_time'] = str_to_datetime(travels['Start_time'])\n",
    "travels['End_time'] = str_to_datetime(travels['End_time'])\n",
    "\n",
    "travels.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando coluna de horas\n",
    "travels['hour'] = travels.Start_time.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando valor de distancia no dataframe\n",
    "distance = []\n",
    "for i in range(len(travels)):\n",
    "    distance.append(haversine(travels['Start_lon'].iloc[i],travels['Start_lat'].iloc[i],\n",
    "                              travels['End_lon'].iloc[i],travels['End_lat'].iloc[i]))\n",
    "travels['distance'] = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing travels that finish in the same place or near where started\n",
    "travels_greatDistance = travels[(travels['distance'] > 150)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hour processed: 0\n",
      "Hour processed: 1\n",
      "Hour processed: 2\n",
      "Hour processed: 3\n",
      "Hour processed: 4\n",
      "Hour processed: 5\n",
      "Hour processed: 6\n",
      "Hour processed: 7\n",
      "Hour processed: 8\n",
      "Hour processed: 9\n",
      "Hour processed: 10\n",
      "Hour processed: 11\n",
      "Hour processed: 12\n",
      "Hour processed: 13\n",
      "Hour processed: 14\n",
      "Hour processed: 15\n",
      "Hour processed: 16\n",
      "Hour processed: 17\n",
      "Hour processed: 18\n",
      "Hour processed: 19\n",
      "Hour processed: 20\n",
      "Hour processed: 21\n",
      "Hour processed: 22\n",
      "Hour processed: 23\n"
     ]
    }
   ],
   "source": [
    "# Creating flux csvs for each hour of day\n",
    "for hour in range(24):\n",
    "    \n",
    "    flux = pd.DataFrame()\n",
    "    for i in range(len(names)):\n",
    "        flux[i] = [0] * len(names)\n",
    "    \n",
    "    hour_data = travels_greatDistance[travels_greatDistance['hour'] == hour]\n",
    "    \n",
    "    for i in range(len(hour_data)):\n",
    "        source = names[names['name'] == hour_data['start_district'].iloc[i]].index[0]\n",
    "        target = names[names['name'] == hour_data['end_district'].iloc[i]].index[0]\n",
    "        flux[target].iloc[source] += 1 \n",
    "        \n",
    "    flux.index = list(names['name'])\n",
    "    flux.columns = list(names['name'])\n",
    "    \n",
    "    print('Hour processed: '+str(hour))\n",
    "        \n",
    "    flux.to_csv('../travels_hotmap/hour_analysis/hour'+str(hour)+'.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
